{
    "sourceFile": "README.md",
    "activeCommit": 0,
    "commits": [
        {
<<<<<<< HEAD
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1716368438953,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1716368456369,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -183,5 +183,7 @@\n   journal={arXiv preprint arXiv:2112.11790},\n   year={2021}\n }\n ```\n+\n+# 多GPU训练\n ![alt text](image.png)\n\\ No newline at end of file\n"
                }
            ],
            "date": 1716368438953,
            "name": "Commit-0",
            "content": "# BEVDet\n\n\n![](./resources/nds-fps-dal.png)\n\n\n## News\n- **2023.11.08** Support DAL for 3D object detection with LiDAR-camera fusion. [[Arxiv](https://arxiv.org/abs/2311.07152)]\n\n- [History](./docs/en/news.md)\n\n## Main Results\n### Nuscenes Detection\n| Config                                                                    | mAP        | NDS        | Latency(ms) | FPS  | Model                                                                                          | Log                                                                                            |\n| ------------------------------------------------------------------------- | ---------- | ---------- | ---- | ---- | ---------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------- |\n| [**BEVDet-R50**](configs/bevdet/bevdet-r50.py)                            | 28.3       | 35.0       | 29.1/4.2/33.3| 30.7 | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) |\n| [**BEVDet-R50-CBGS**](configs/bevdet/bevdet-r50-cbgs.py)                  | 31.3       | 39.8       |28.9/4.3/33.2 |30.1 | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) |\n| [**BEVDet-R50-4D-CBGS**](configs/bevdet/bevdet-r50-4d-cbgs.py) | 31.4/35.4# | 44.7/44.9# | 29.1/4.3/33.4|30.0 | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) |[baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1)|\n| [**BEVDet-R50-4D-Depth-CBGS**](configs/bevdet/bevdet-r50-4d-depth-cbgs.py) | 36.1/36.2# | 48.3/48.4# |35.7/4.0/39.7 |25.2 | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) |\n| [**BEVDet-R50-4D-Stereo-CBGS**](configs/bevdet/bevdet-r50-4d-stereo-cbgs.py) | 38.2/38.4# | 49.9/50.0# |-  |-  | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) |\n| [**BEVDet-R50-4DLongterm-CBGS**](configs/bevdet/bevdet-r50-4dlongterm-cbgs.py) | 34.8/35.4# | 48.2/48.7# | 30.8/4.2/35.0|28.6 | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) |\n| [**BEVDet-R50-4DLongterm-Depth-CBGS**](configs/bevdet/bevdet-r50-4d-depth-cbgs.py) | 39.4/39.9# | 51.5/51.9# |38.4/4.0/42.4 |23.6 | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) |\n| [**BEVDet-R50-4DLongterm-Stereo-CBGS**](configs/bevdet/bevdet-r50-4dlongterm-stereo-cbgs.py) | 41.1/41.5# | 52.3/52.7# |- |- | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) |\n| [**BEVDet-STBase-4D-Stereo-512x1408-CBGS**](configs/bevdet/bevdet-stbase-4d-stereo-512x1408-cbgs.py) | 47.2# | 57.6# |-  |-  | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) |\n||\n| [**DAL-Tiny**](configs/dal/dal-tiny.py) | 67.4 | 71.3 |-  |16.6 | [baidu](https://pan.baidu.com/s/15rmJL_SWUeQEXG9dYYl8gA?pwd=36g5) | [baidu](https://pan.baidu.com/s/15rmJL_SWUeQEXG9dYYl8gA?pwd=36g5) |\n| [**DAL-Base**](configs/dal/dal-base.py) | 70.0 | 73.4 |-  |10.7 | [baidu](https://pan.baidu.com/s/15rmJL_SWUeQEXG9dYYl8gA?pwd=36g5) | [baidu](https://pan.baidu.com/s/15rmJL_SWUeQEXG9dYYl8gA?pwd=36g5) |\n| [**DAL-Large**](configs/dal/dal-large.py) | 71.5 | 74.0 |-  |6.10 | [baidu](https://pan.baidu.com/s/15rmJL_SWUeQEXG9dYYl8gA?pwd=36g5) | [baidu](https://pan.baidu.com/s/15rmJL_SWUeQEXG9dYYl8gA?pwd=36g5) |\n\n\\# align previous frame bev feature during the view transformation.\n\nDepth: Depth supervised from Lidar as BEVDepth.\n\nLongterm: cat 8 history frame in temporal modeling. 1 by default. \n\nStereo: A private implementation that concat cost-volumn with image feature before executing model.view_transformer.depth_net.\n\nThe latency includes Network/Post-Processing/Total. Training without CBGS is deprecated.\n\n\n### Nuscenes Occupancy\n| Config                                                                    | mIOU       | Model | Log                                                                                            |\n| ------------------------------------------------------------------------- | ---------- | ---------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------- |\n| [**BEVDet-Occ-R50-4D-Stereo-2x**](configs/bevdet_occ/bevdet-occ-r50-4d-stereo-24e.py)                                 | 36.1     | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) |\n| [**BEVDet-Occ-R50-4D-Stereo-2x-384x704**](configs/bevdet_occ/bevdet-occ-r50-4d-stereo-24e_384704.py)                  | 37.3     | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) |\n| [**BEVDet-Occ-R50-4DLongterm-Stereo-2x-384x704**](configs/bevdet_occ/bevdet-occ-r50-4dlongterm-stereo-24e_384704.py)  | 39.3     | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) |\n| [**BEVDet-Occ-STBase-4D-Stereo-2x**](configs/bevdet_occ/bevdet-occ-stbase-4d-stereo-512x1408-24e.py)                  | 42.0     | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) | [baidu](https://pan.baidu.com/s/1237QyV18zvRJ1pU3YzRItw?pwd=npe1) |\n## Inference latency with different backends\n\n| Backend       | 256x704 | 384x1056 | 512x1408 | 640x1760 |\n| ------------- | ------- | -------- | -------- | -------- |\n| PyTorch       | 28.9    | 49.7     | 78.7    | 113.4    |\n| TensorRT      | 14.0    | 22.8     | 36.5     | 53.0     |\n| TensorRT-FP16 | 4.94     | 7.96     | 12.4     | 17.9     |\n| TensorRT-INT8 | 2.93    | 4.41      | 6.58      | 9.19     |                                      \n| TensorRT-INT8(Xavier) | 25.0    | -      | -     | -    | \n\n- Evaluate with [**BEVDet-R50-CBGS**](configs/bevdet/bevdet-r50-cbgs.py) on a RTX 3090 GPU by default. We omit the postprocessing, which spends up to 5 ms with the PyTorch backend.\n\n## Get Started\n\n#### Installation and Data Preparation\n\nstep 1. Please prepare environment as that in [Docker](docker/Dockerfile).\n\nstep 2. Prepare bevdet repo by.\n```shell script\ngit clone https://github.com/HuangJunJie2017/BEVDet.git\ncd BEVDet\npip install -v -e .\n```\n\nstep 3. Prepare nuScenes dataset as introduced in [nuscenes_det.md](docs/en/datasets/nuscenes_det.md) and create the pkl for BEVDet by running:\n```shell\npython tools/create_data_bevdet.py\n```\nstep 4. For Occupancy Prediction task, download (only) the 'gts' from [CVPR2023-3D-Occupancy-Prediction](https://github.com/CVPR2023-3D-Occupancy-Prediction/CVPR2023-3D-Occupancy-Prediction) and arrange the folder as:\n```shell script\n└── nuscenes\n    ├── v1.0-trainval (existing)\n    ├── sweeps  (existing)\n    ├── samples (existing)\n    └── gts (new)\n```\n\n#### Train model\n```shell\n# single gpu\npython tools/train.py $config\n# multiple gpu\n./tools/dist_train.sh $config num_gpu\n```\n\n#### Test model\n```shell\n# single gpu\npython tools/test.py $config $checkpoint --eval mAP\n# multiple gpu\n./tools/dist_test.sh $config $checkpoint num_gpu --eval mAP\n```\n\n#### Estimate the inference speed of BEVDet\n\n```shell\n# with pre-computation acceleration\npython tools/analysis_tools/benchmark.py $config $checkpoint --fuse-conv-bn\n# 4D with pre-computation acceleration\npython tools/analysis_tools/benchmark_sequential.py $config $checkpoint --fuse-conv-bn\n# view transformer only\npython tools/analysis_tools/benchmark_view_transformer.py $config $checkpoint\n```\n\n#### Estimate the flops of BEVDet\n\n```shell\npython tools/analysis_tools/get_flops.py configs/bevdet/bevdet-r50.py --shape 256 704\n```\n\n#### Visualize the predicted result.\n\n- Private implementation. (Visualization remotely/locally)\n\n```shell\npython tools/test.py $config $checkpoint --format-only --eval-options jsonfile_prefix=$savepath\npython tools/analysis_tools/vis.py $savepath/pts_bbox/results_nusc.json\n```\n\n#### Convert to TensorRT and test inference speed.\n\n```shell\n1. install mmdeploy from https://github.com/HuangJunJie2017/mmdeploy\n2. convert to TensorRT\npython tools/convert_bevdet_to_TRT.py $config $checkpoint $work_dir --fuse-conv-bn --fp16 --int8\n3. test inference speed\npython tools/analysis_tools/benchmark_trt.py $config $engine\n```\n\n## Acknowledgement\n\nThis project is not possible without multiple great open-sourced code bases. We list some notable examples below.\n\n- [open-mmlab](https://github.com/open-mmlab)\n- [CenterPoint](https://github.com/tianweiy/CenterPoint)\n- [Lift-Splat-Shoot](https://github.com/nv-tlabs/lift-splat-shoot)\n- [Swin Transformer](https://github.com/microsoft/Swin-Transformer)\n- [BEVFusion](https://github.com/mit-han-lab/bevfusion)\n- [BEVDepth](https://github.com/Megvii-BaseDetection/BEVDepth)\n\nBeside, there are some other attractive works extend the boundary of BEVDet.\n\n- [BEVerse](https://github.com/zhangyp15/BEVerse)  for multi-task learning.\n- [BEVStereo](https://github.com/Megvii-BaseDetection/BEVStereo)  for stero depth estimation.\n\n## Bibtex\n\nIf this work is helpful for your research, please consider citing the following BibTeX entries.\n\n```\n@article{huang2023dal,\n  title={Detecting As Labeling: Rethinking LiDAR-camera Fusion in 3D Object Detection},\n  author={Huang, Junjie and Ye, Yun and Liang, Zhujin and Shan, Yi and Du, Dalong},\n  journal={arXiv preprint arXiv:2311.07152},\n  year={2023}\n}\n\n@article{huang2022bevpoolv2,\n  title={BEVPoolv2: A Cutting-edge Implementation of BEVDet Toward Deployment},\n  author={Huang, Junjie and Huang, Guan},\n  journal={arXiv preprint arXiv:2211.17111},\n  year={2022}\n}\n\n@article{huang2022bevdet4d,\n  title={BEVDet4D: Exploit Temporal Cues in Multi-camera 3D Object Detection},\n  author={Huang, Junjie and Huang, Guan},\n  journal={arXiv preprint arXiv:2203.17054},\n  year={2022}\n}\n\n@article{huang2021bevdet,\n  title={BEVDet: High-performance Multi-camera 3D Object Detection in Bird-Eye-View},\n  author={Huang, Junjie and Huang, Guan and Zhu, Zheng and Yun, Ye and Du, Dalong},\n  journal={arXiv preprint arXiv:2112.11790},\n  year={2021}\n}\n```\n![alt text](image.png)"
=======
            "activePatchIndex": 4,
            "patches": [
                {
                    "date": 1734153162166,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1734153503730,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,13 @@\n+# D3PD\r\n+\r\n+The official implementation of the paper [D3PD: Dual Distillation and Dynamic Fusion of Camera and Radar for 3D Perception Detection]\r\n+\r\n+## Installation\r\n+Please check [installation](docs/installation.md) for installation and [data_preparation](docs/data_preparation.md) for preparing the nuScenes dataset.\r\n+\r\n+## Getting Started\r\n+Please check [getting_started](docs/getting_started.md) for training, evaluation, and visualization of D3PD.\r\n+\r\n+\r\n+## Acknowledgement\r\n+This project is mainly based on the following open-sourced projects: [open-mmlab](https://github.com/open-mmlab), [BEVDet](https://github.com/HuangJunJie2017/BEVDet).\r\n"
                },
                {
                    "date": 1734153515288,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,14 @@\n+# D3PD\r\n+\r\n+The official implementation of the paper [D3PD: Dual Distillation and Dynamic Fusion of Camera and Radar for 3D Perception Detection]\r\n+\r\n+\r\n+## Installation\r\n+Please check [installation](docs/installation.md) for installation and [data_preparation](docs/data_preparation.md) for preparing the nuScenes dataset.\r\n+\r\n+## Getting Started\r\n+Please check [getting_started](docs/getting_started.md) for training, evaluation, and visualization of D3PD.\r\n+\r\n+\r\n+## Acknowledgement\r\n+This project is mainly based on the following open-sourced projects: [open-mmlab](https://github.com/open-mmlab), [BEVDet](https://github.com/HuangJunJie2017/BEVDet).\r\n"
                },
                {
                    "date": 1734153528747,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -11,30 +11,4 @@\n \r\n \r\n ## Acknowledgement\r\n This project is mainly based on the following open-sourced projects: [open-mmlab](https://github.com/open-mmlab), [BEVDet](https://github.com/HuangJunJie2017/BEVDet).\r\n-# D3PD\r\n-\r\n-The official implementation of the paper [D3PD: Dual Distillation and Dynamic Fusion of Camera and Radar for 3D Perception Detection]\r\n-\r\n-## Installation\r\n-Please check [installation](docs/installation.md) for installation and [data_preparation](docs/data_preparation.md) for preparing the nuScenes dataset.\r\n-\r\n-## Getting Started\r\n-Please check [getting_started](docs/getting_started.md) for training, evaluation, and visualization of D3PD.\r\n-\r\n-\r\n-## Acknowledgement\r\n-This project is mainly based on the following open-sourced projects: [open-mmlab](https://github.com/open-mmlab), [BEVDet](https://github.com/HuangJunJie2017/BEVDet).\r\n-# D3PD\r\n-\r\n-The official implementation of the paper [D3PD: Dual Distillation and Dynamic Fusion of Camera and Radar for 3D Perception Detection]\r\n-\r\n-## Installation\r\n-Please check [installation](docs/installation.md) for installation and [data_preparation](docs/data_preparation.md) for preparing the nuScenes dataset.\r\n-\r\n-## Getting Started\r\n-Please check [getting_started](docs/getting_started.md) for training, evaluation, and visualization of D3PD.\r\n-\r\n-\r\n-## Acknowledgement\r\n-This project is mainly based on the following open-sourced projects: [open-mmlab](https://github.com/open-mmlab), [BEVDet](https://github.com/HuangJunJie2017/BEVDet).\r\n"
                },
                {
                    "date": 1734153577604,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,9 +1,9 @@\n # D3PD\r\n \r\n The official implementation of the paper [D3PD: Dual Distillation and Dynamic Fusion of Camera and Radar for 3D Perception Detection]\r\n+![D3PD](/docs/overrall.png \"D3PD\")\r\n \r\n-\r\n ## Installation\r\n Please check [installation](docs/installation.md) for installation and [data_preparation](docs/data_preparation.md) for preparing the nuScenes dataset.\r\n \r\n ## Getting Started\r\n"
                }
            ],
            "date": 1734153162166,
            "name": "Commit-0",
            "content": "# D3PD\r\n\r\nThe official implementation of the paper [D3PD: Dual Distillation and Dynamic Fusion of Camera and Radar for 3D Perception Detection]\r\n\r\n## Installation\r\nPlease check [installation](docs/installation.md) for installation and [data_preparation](docs/data_preparation.md) for preparing the nuScenes dataset.\r\n\r\n## Getting Started\r\nPlease check [getting_started](docs/getting_started.md) for training, evaluation, and visualization of D3PD.\r\n\r\n\r\n## Acknowledgement\r\nThis project is mainly based on the following open-sourced projects: [open-mmlab](https://github.com/open-mmlab), [BEVDet](https://github.com/HuangJunJie2017/BEVDet).\r\n"
>>>>>>> ba38bb592efd76d1c4f0f3d55f760297377ec0a5
        }
    ]
}