{
    "sourceFile": "tools/data_converter/create_gt_database.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1716014087888,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1719994046734,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -19,9 +19,9 @@\n         # polygon -- a single object might consist of multiple parts\n         # we merge all parts into one mask rle code\n         rles = maskUtils.frPyObjects(mask_ann, img_h, img_w)\n         rle = maskUtils.merge(rles)\n-    elif isinstance(mask_ann['counts'], list):\n+    elif isinstance(mask_ann[\"counts\"], list):\n         # uncompressed RLE\n         rle = maskUtils.frPyObjects(mask_ann, img_h, img_w)\n     else:\n         # rle\n@@ -36,19 +36,19 @@\n     gt_bboxes_ignore = []\n     gt_masks_ann = []\n \n     for i, ann in enumerate(ann_info):\n-        if ann.get('ignore', False):\n+        if ann.get(\"ignore\", False):\n             continue\n-        x1, y1, w, h = ann['bbox']\n-        if ann['area'] <= 0:\n+        x1, y1, w, h = ann[\"bbox\"]\n+        if ann[\"area\"] <= 0:\n             continue\n         bbox = [x1, y1, x1 + w, y1 + h]\n-        if ann.get('iscrowd', False):\n+        if ann.get(\"iscrowd\", False):\n             gt_bboxes_ignore.append(bbox)\n         else:\n             gt_bboxes.append(bbox)\n-            gt_masks_ann.append(ann['segmentation'])\n+            gt_masks_ann.append(ann[\"segmentation\"])\n \n     if gt_bboxes:\n         gt_bboxes = np.array(gt_bboxes, dtype=np.float32)\n         gt_labels = np.array(gt_labels, dtype=np.int64)\n@@ -60,31 +60,33 @@\n         gt_bboxes_ignore = np.array(gt_bboxes_ignore, dtype=np.float32)\n     else:\n         gt_bboxes_ignore = np.zeros((0, 4), dtype=np.float32)\n \n-    ann = dict(\n-        bboxes=gt_bboxes, bboxes_ignore=gt_bboxes_ignore, masks=gt_masks_ann)\n+    ann = dict(bboxes=gt_bboxes, bboxes_ignore=gt_bboxes_ignore, masks=gt_masks_ann)\n \n     return ann\n \n \n def crop_image_patch_v2(pos_proposals, pos_assigned_gt_inds, gt_masks):\n     import torch\n     from torch.nn.modules.utils import _pair\n+\n     device = pos_proposals.device\n     num_pos = pos_proposals.size(0)\n-    fake_inds = (\n-        torch.arange(num_pos,\n-                     device=device).to(dtype=pos_proposals.dtype)[:, None])\n+    fake_inds = torch.arange(num_pos, device=device).to(dtype=pos_proposals.dtype)[\n+        :, None\n+    ]\n     rois = torch.cat([fake_inds, pos_proposals], dim=1)  # Nx5\n     mask_size = _pair(28)\n     rois = rois.to(device=device)\n     gt_masks_th = (\n-        torch.from_numpy(gt_masks).to(device).index_select(\n-            0, pos_assigned_gt_inds).to(dtype=rois.dtype))\n+        torch.from_numpy(gt_masks)\n+        .to(device)\n+        .index_select(0, pos_assigned_gt_inds)\n+        .to(dtype=rois.dtype)\n+    )\n     # Use RoIAlign could apparently accelerate the training (~0.1s/iter)\n-    targets = (\n-        roi_align(gt_masks_th, rois, mask_size[::-1], 1.0, 0, True).squeeze(1))\n+    targets = roi_align(gt_masks_th, rois, mask_size[::-1], 1.0, 0, True).squeeze(1)\n     return targets\n \n \n def crop_image_patch(pos_proposals, gt_masks, pos_assigned_gt_inds, org_img):\n@@ -97,21 +99,18 @@\n         x1, y1, x2, y2 = bbox\n         w = np.maximum(x2 - x1 + 1, 1)\n         h = np.maximum(y2 - y1 + 1, 1)\n \n-        mask_patch = gt_mask[y1:y1 + h, x1:x1 + w]\n+        mask_patch = gt_mask[y1 : y1 + h, x1 : x1 + w]\n         masked_img = gt_mask[..., None] * org_img\n-        img_patch = masked_img[y1:y1 + h, x1:x1 + w]\n+        img_patch = masked_img[y1 : y1 + h, x1 : x1 + w]\n \n         img_patches.append(img_patch)\n         masks.append(mask_patch)\n     return img_patches, masks\n \n \n-def create_groundtruth_database(dataset_class_name,\n-                                data_path,\n-                                info_prefix,\n-                                info_path):\n+def create_groundtruth_database(dataset_class_name, data_path, info_prefix, info_path):\n     \"\"\"Given the raw data, generate the ground truth database.\n \n     Args:\n         dataset_class_name (str): Name of the input dataset.\n@@ -135,51 +134,53 @@\n     used_classes = None\n     database_save_path = None\n     db_info_save_path = None\n \n-    print(f'Create GT Database of {dataset_class_name}')\n-    CLASSES = ('car', 'truck', 'construction_vehicle', 'bus', 'trailer',\n-        'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone')\n+    print(f\"Create GT Database of {dataset_class_name}\")\n+    CLASSES = (\n+        \"car\",\n+        \"truck\",\n+        \"construction_vehicle\",\n+        \"bus\",\n+        \"trailer\",\n+        \"barrier\",\n+        \"motorcycle\",\n+        \"bicycle\",\n+        \"pedestrian\",\n+        \"traffic_cone\",\n+    )\n \n-    dataset_cfg = dict(\n-        type=dataset_class_name, data_root=data_path, ann_file=info_path)\n+    dataset_cfg = dict(type=dataset_class_name, data_root=data_path, ann_file=info_path)\n     dataset_cfg.update(\n         use_valid_flag=True,\n         modality=dict(\n-                    use_lidar=True,\n-                    use_camera=True,\n-                    use_radar=False,\n-                    use_map=False,\n-                    use_external=False),\n-        img_info_prototype='bevdet',\n+            use_lidar=True,\n+            use_camera=True,\n+            use_radar=False,\n+            use_map=False,\n+            use_external=False,\n+        ),\n+        img_info_prototype=\"bevdet\",\n         pipeline=[\n+            dict(type=\"LoadPointsFromFile\", coord_type=\"LIDAR\", load_dim=5, use_dim=5),\n             dict(\n-                type='LoadPointsFromFile',\n-                coord_type='LIDAR',\n-                load_dim=5,\n-                use_dim=5),\n-            dict(\n-                type='LoadPointsFromMultiSweeps',\n+                type=\"LoadPointsFromMultiSweeps\",\n                 sweeps_num=10,\n                 use_dim=[0, 1, 2, 3, 4],\n                 pad_empty_sweeps=True,\n-                remove_close=True),\n-            dict(type='ToEgo'),\n-            dict(type='LoadAnnotations'),\n-            dict(\n-                type='BEVAug',\n-                bda_aug_conf=None,\n-                classes=[],\n-                is_train=False\n+                remove_close=True,\n             ),\n-        ])\n+            dict(type=\"ToEgo\"),\n+            dict(type=\"LoadAnnotations\"),\n+            dict(type=\"BEVAug\", bda_aug_conf=None, classes=[], is_train=False),\n+        ],\n+    )\n     dataset = build_dataset(dataset_cfg)\n \n     if database_save_path is None:\n-        database_save_path = osp.join(data_path, f'{info_prefix}_gt_database')\n+        database_save_path = osp.join(data_path, f\"{info_prefix}_gt_database\")\n     if db_info_save_path is None:\n-        db_info_save_path = osp.join(data_path,\n-                                     f'{info_prefix}_dbinfos_train.pkl')\n+        db_info_save_path = osp.join(data_path, f\"{info_prefix}_dbinfos_train.pkl\")\n     mmcv.mkdir_or_exist(database_save_path)\n     all_db_infos = dict()\n \n     group_counter = 0\n@@ -187,36 +188,36 @@\n         input_dict = dataset.get_data_info(j)\n         dataset.pre_pipeline(input_dict)\n         example = dataset.pipeline(input_dict)\n         annos = dict(\n-            gt_bboxes_3d=example['gt_bboxes_3d'],\n-            gt_labels_3d=example['gt_labels_3d'],\n-            gt_names=[CLASSES[cid] for cid in example['gt_labels_3d']]\n+            gt_bboxes_3d=example[\"gt_bboxes_3d\"],\n+            gt_labels_3d=example[\"gt_labels_3d\"],\n+            gt_names=[CLASSES[cid] for cid in example[\"gt_labels_3d\"]],\n         )\n-        image_idx = example['sample_idx']\n-        points = example['points'].tensor.numpy()\n-        gt_boxes_3d = annos['gt_bboxes_3d'].tensor.numpy()\n-        names = annos['gt_names']\n+        image_idx = example[\"sample_idx\"]\n+        points = example[\"points\"].tensor.numpy()\n+        gt_boxes_3d = annos[\"gt_bboxes_3d\"].tensor.numpy()\n+        names = annos[\"gt_names\"]\n         group_dict = dict()\n-        if 'group_ids' in annos:\n-            group_ids = annos['group_ids']\n+        if \"group_ids\" in annos:\n+            group_ids = annos[\"group_ids\"]\n         else:\n             group_ids = np.arange(gt_boxes_3d.shape[0], dtype=np.int64)\n         difficulty = np.zeros(gt_boxes_3d.shape[0], dtype=np.int32)\n-        if 'difficulty' in annos:\n-            difficulty = annos['difficulty']\n+        if \"difficulty\" in annos:\n+            difficulty = annos[\"difficulty\"]\n \n         # enlarge the bbox acoording to the instance motion\n         num_obj = gt_boxes_3d.shape[0]\n         gt_boxes_3d_range = gt_boxes_3d.copy()\n         relative_velocity = gt_boxes_3d_range[:, 7:]\n         relative_offset = relative_velocity * 0.5\n-        yaw = gt_boxes_3d_range[:,6]\n+        yaw = gt_boxes_3d_range[:, 6]\n         s = np.sin(yaw)\n         c = np.cos(yaw)\n         rot = np.stack([c, s, -s, c], axis=-1)\n         rot = rot.reshape(num_obj, 2, 2)\n-        size_offset = rot @ relative_offset.reshape(num_obj,2,1)\n+        size_offset = rot @ relative_offset.reshape(num_obj, 2, 1)\n         size_offset = np.abs(size_offset.reshape(num_obj, 2))\n \n         gt_boxes_3d_range[:, 3:5] = gt_boxes_3d_range[:, 3:5] + size_offset\n         gt_boxes_3d_range[:, :2] = gt_boxes_3d_range[:, :2] - relative_offset * 0.5\n@@ -225,43 +226,43 @@\n \n         # vis_points_all(lidar_points=points.copy(), boxes=annos['gt_bboxes_3d'], input_img=input_img)\n \n         for i in range(num_obj):\n-            filename = f'{image_idx}_{names[i]}_{i}.bin'\n+            filename = f\"{image_idx}_{names[i]}_{i}.bin\"\n             abs_filepath = osp.join(database_save_path, filename)\n-            rel_filepath = osp.join(f'{info_prefix}_gt_database', filename)\n+            rel_filepath = osp.join(f\"{info_prefix}_gt_database\", filename)\n \n             # save point clouds and image patches for each object\n             gt_points = points[point_indices[:, i]]\n             gt_points[:, :3] -= gt_boxes_3d[i, :3]\n \n-            with open(abs_filepath, 'w') as f:\n+            with open(abs_filepath, \"w\") as f:\n                 gt_points.tofile(f)\n \n             if (used_classes is None) or names[i] in used_classes:\n                 db_info = {\n-                    'name': names[i],\n-                    'path': rel_filepath,\n-                    'image_idx': image_idx,\n-                    'gt_idx': i,\n-                    'box3d_lidar': gt_boxes_3d[i],\n-                    'num_points_in_gt': gt_points.shape[0],\n-                    'difficulty': difficulty[i],\n+                    \"name\": names[i],\n+                    \"path\": rel_filepath,\n+                    \"image_idx\": image_idx,\n+                    \"gt_idx\": i,\n+                    \"box3d_lidar\": gt_boxes_3d[i],\n+                    \"num_points_in_gt\": gt_points.shape[0],\n+                    \"difficulty\": difficulty[i],\n                 }\n                 local_group_id = group_ids[i]\n                 # if local_group_id >= 0:\n                 if local_group_id not in group_dict:\n                     group_dict[local_group_id] = group_counter\n                     group_counter += 1\n-                db_info['group_id'] = group_dict[local_group_id]\n-                if 'score' in annos:\n-                    db_info['score'] = annos['score'][i]\n+                db_info[\"group_id\"] = group_dict[local_group_id]\n+                if \"score\" in annos:\n+                    db_info[\"score\"] = annos[\"score\"][i]\n                 if names[i] in all_db_infos:\n                     all_db_infos[names[i]].append(db_info)\n                 else:\n                     all_db_infos[names[i]] = [db_info]\n \n     for k, v in all_db_infos.items():\n-        print(f'load {len(v)} {k} database infos')\n+        print(f\"load {len(v)} {k} database infos\")\n \n-    with open(db_info_save_path, 'wb') as f:\n+    with open(db_info_save_path, \"wb\") as f:\n         pickle.dump(all_db_infos, f)\n"
                }
            ],
            "date": 1716014087888,
            "name": "Commit-0",
            "content": "# Copyright (c) OpenMMLab. All rights reserved.\nimport pickle\nfrom os import path as osp\n\nimport mmcv\nimport numpy as np\nfrom mmcv import track_iter_progress\nfrom mmcv.ops import roi_align\nfrom pycocotools import mask as maskUtils\nfrom pycocotools.coco import COCO\nfrom pyquaternion.quaternion import Quaternion\nfrom mmdet3d.core.bbox import box_np_ops as box_np_ops\nfrom mmdet3d.datasets import build_dataset\nfrom mmdet.core.evaluation.bbox_overlaps import bbox_overlaps\n\n\ndef _poly2mask(mask_ann, img_h, img_w):\n    if isinstance(mask_ann, list):\n        # polygon -- a single object might consist of multiple parts\n        # we merge all parts into one mask rle code\n        rles = maskUtils.frPyObjects(mask_ann, img_h, img_w)\n        rle = maskUtils.merge(rles)\n    elif isinstance(mask_ann['counts'], list):\n        # uncompressed RLE\n        rle = maskUtils.frPyObjects(mask_ann, img_h, img_w)\n    else:\n        # rle\n        rle = mask_ann\n    mask = maskUtils.decode(rle)\n    return mask\n\n\ndef _parse_coco_ann_info(ann_info):\n    gt_bboxes = []\n    gt_labels = []\n    gt_bboxes_ignore = []\n    gt_masks_ann = []\n\n    for i, ann in enumerate(ann_info):\n        if ann.get('ignore', False):\n            continue\n        x1, y1, w, h = ann['bbox']\n        if ann['area'] <= 0:\n            continue\n        bbox = [x1, y1, x1 + w, y1 + h]\n        if ann.get('iscrowd', False):\n            gt_bboxes_ignore.append(bbox)\n        else:\n            gt_bboxes.append(bbox)\n            gt_masks_ann.append(ann['segmentation'])\n\n    if gt_bboxes:\n        gt_bboxes = np.array(gt_bboxes, dtype=np.float32)\n        gt_labels = np.array(gt_labels, dtype=np.int64)\n    else:\n        gt_bboxes = np.zeros((0, 4), dtype=np.float32)\n        gt_labels = np.array([], dtype=np.int64)\n\n    if gt_bboxes_ignore:\n        gt_bboxes_ignore = np.array(gt_bboxes_ignore, dtype=np.float32)\n    else:\n        gt_bboxes_ignore = np.zeros((0, 4), dtype=np.float32)\n\n    ann = dict(\n        bboxes=gt_bboxes, bboxes_ignore=gt_bboxes_ignore, masks=gt_masks_ann)\n\n    return ann\n\n\ndef crop_image_patch_v2(pos_proposals, pos_assigned_gt_inds, gt_masks):\n    import torch\n    from torch.nn.modules.utils import _pair\n    device = pos_proposals.device\n    num_pos = pos_proposals.size(0)\n    fake_inds = (\n        torch.arange(num_pos,\n                     device=device).to(dtype=pos_proposals.dtype)[:, None])\n    rois = torch.cat([fake_inds, pos_proposals], dim=1)  # Nx5\n    mask_size = _pair(28)\n    rois = rois.to(device=device)\n    gt_masks_th = (\n        torch.from_numpy(gt_masks).to(device).index_select(\n            0, pos_assigned_gt_inds).to(dtype=rois.dtype))\n    # Use RoIAlign could apparently accelerate the training (~0.1s/iter)\n    targets = (\n        roi_align(gt_masks_th, rois, mask_size[::-1], 1.0, 0, True).squeeze(1))\n    return targets\n\n\ndef crop_image_patch(pos_proposals, gt_masks, pos_assigned_gt_inds, org_img):\n    num_pos = pos_proposals.shape[0]\n    masks = []\n    img_patches = []\n    for i in range(num_pos):\n        gt_mask = gt_masks[pos_assigned_gt_inds[i]]\n        bbox = pos_proposals[i, :].astype(np.int32)\n        x1, y1, x2, y2 = bbox\n        w = np.maximum(x2 - x1 + 1, 1)\n        h = np.maximum(y2 - y1 + 1, 1)\n\n        mask_patch = gt_mask[y1:y1 + h, x1:x1 + w]\n        masked_img = gt_mask[..., None] * org_img\n        img_patch = masked_img[y1:y1 + h, x1:x1 + w]\n\n        img_patches.append(img_patch)\n        masks.append(mask_patch)\n    return img_patches, masks\n\n\ndef create_groundtruth_database(dataset_class_name,\n                                data_path,\n                                info_prefix,\n                                info_path):\n    \"\"\"Given the raw data, generate the ground truth database.\n\n    Args:\n        dataset_class_name (str): Name of the input dataset.\n        data_path (str): Path of the data.\n        info_prefix (str): Prefix of the info file.\n        info_path (str, optional): Path of the info file.\n            Default: None.\n        mask_anno_path (str, optional): Path of the mask_anno.\n            Default: None.\n        used_classes (list[str], optional): Classes have been used.\n            Default: None.\n        database_save_path (str, optional): Path to save database.\n            Default: None.\n        db_info_save_path (str, optional): Path to save db_info.\n            Default: None.\n        relative_path (bool, optional): Whether to use relative path.\n            Default: True.\n        with_mask (bool, optional): Whether to use mask.\n            Default: False.\n    \"\"\"\n    used_classes = None\n    database_save_path = None\n    db_info_save_path = None\n\n    print(f'Create GT Database of {dataset_class_name}')\n    CLASSES = ('car', 'truck', 'construction_vehicle', 'bus', 'trailer',\n        'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone')\n\n    dataset_cfg = dict(\n        type=dataset_class_name, data_root=data_path, ann_file=info_path)\n    dataset_cfg.update(\n        use_valid_flag=True,\n        modality=dict(\n                    use_lidar=True,\n                    use_camera=True,\n                    use_radar=False,\n                    use_map=False,\n                    use_external=False),\n        img_info_prototype='bevdet',\n        pipeline=[\n            dict(\n                type='LoadPointsFromFile',\n                coord_type='LIDAR',\n                load_dim=5,\n                use_dim=5),\n            dict(\n                type='LoadPointsFromMultiSweeps',\n                sweeps_num=10,\n                use_dim=[0, 1, 2, 3, 4],\n                pad_empty_sweeps=True,\n                remove_close=True),\n            dict(type='ToEgo'),\n            dict(type='LoadAnnotations'),\n            dict(\n                type='BEVAug',\n                bda_aug_conf=None,\n                classes=[],\n                is_train=False\n            ),\n        ])\n    dataset = build_dataset(dataset_cfg)\n\n    if database_save_path is None:\n        database_save_path = osp.join(data_path, f'{info_prefix}_gt_database')\n    if db_info_save_path is None:\n        db_info_save_path = osp.join(data_path,\n                                     f'{info_prefix}_dbinfos_train.pkl')\n    mmcv.mkdir_or_exist(database_save_path)\n    all_db_infos = dict()\n\n    group_counter = 0\n    for j in track_iter_progress(list(range(len(dataset)))):\n        input_dict = dataset.get_data_info(j)\n        dataset.pre_pipeline(input_dict)\n        example = dataset.pipeline(input_dict)\n        annos = dict(\n            gt_bboxes_3d=example['gt_bboxes_3d'],\n            gt_labels_3d=example['gt_labels_3d'],\n            gt_names=[CLASSES[cid] for cid in example['gt_labels_3d']]\n        )\n        image_idx = example['sample_idx']\n        points = example['points'].tensor.numpy()\n        gt_boxes_3d = annos['gt_bboxes_3d'].tensor.numpy()\n        names = annos['gt_names']\n        group_dict = dict()\n        if 'group_ids' in annos:\n            group_ids = annos['group_ids']\n        else:\n            group_ids = np.arange(gt_boxes_3d.shape[0], dtype=np.int64)\n        difficulty = np.zeros(gt_boxes_3d.shape[0], dtype=np.int32)\n        if 'difficulty' in annos:\n            difficulty = annos['difficulty']\n\n        # enlarge the bbox acoording to the instance motion\n        num_obj = gt_boxes_3d.shape[0]\n        gt_boxes_3d_range = gt_boxes_3d.copy()\n        relative_velocity = gt_boxes_3d_range[:, 7:]\n        relative_offset = relative_velocity * 0.5\n        yaw = gt_boxes_3d_range[:,6]\n        s = np.sin(yaw)\n        c = np.cos(yaw)\n        rot = np.stack([c, s, -s, c], axis=-1)\n        rot = rot.reshape(num_obj, 2, 2)\n        size_offset = rot @ relative_offset.reshape(num_obj,2,1)\n        size_offset = np.abs(size_offset.reshape(num_obj, 2))\n\n        gt_boxes_3d_range[:, 3:5] = gt_boxes_3d_range[:, 3:5] + size_offset\n        gt_boxes_3d_range[:, :2] = gt_boxes_3d_range[:, :2] - relative_offset * 0.5\n\n        point_indices = box_np_ops.points_in_rbbox(points, gt_boxes_3d_range)\n\n        # vis_points_all(lidar_points=points.copy(), boxes=annos['gt_bboxes_3d'], input_img=input_img)\n\n        for i in range(num_obj):\n            filename = f'{image_idx}_{names[i]}_{i}.bin'\n            abs_filepath = osp.join(database_save_path, filename)\n            rel_filepath = osp.join(f'{info_prefix}_gt_database', filename)\n\n            # save point clouds and image patches for each object\n            gt_points = points[point_indices[:, i]]\n            gt_points[:, :3] -= gt_boxes_3d[i, :3]\n\n            with open(abs_filepath, 'w') as f:\n                gt_points.tofile(f)\n\n            if (used_classes is None) or names[i] in used_classes:\n                db_info = {\n                    'name': names[i],\n                    'path': rel_filepath,\n                    'image_idx': image_idx,\n                    'gt_idx': i,\n                    'box3d_lidar': gt_boxes_3d[i],\n                    'num_points_in_gt': gt_points.shape[0],\n                    'difficulty': difficulty[i],\n                }\n                local_group_id = group_ids[i]\n                # if local_group_id >= 0:\n                if local_group_id not in group_dict:\n                    group_dict[local_group_id] = group_counter\n                    group_counter += 1\n                db_info['group_id'] = group_dict[local_group_id]\n                if 'score' in annos:\n                    db_info['score'] = annos['score'][i]\n                if names[i] in all_db_infos:\n                    all_db_infos[names[i]].append(db_info)\n                else:\n                    all_db_infos[names[i]] = [db_info]\n\n    for k, v in all_db_infos.items():\n        print(f'load {len(v)} {k} database infos')\n\n    with open(db_info_save_path, 'wb') as f:\n        pickle.dump(all_db_infos, f)\n"
        }
    ]
}