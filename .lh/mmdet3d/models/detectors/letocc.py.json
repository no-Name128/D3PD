{
    "sourceFile": "mmdet3d/models/detectors/letocc.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 9,
            "patches": [
                {
                    "date": 1720689643857,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1720778561984,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -18,8 +18,9 @@\n         use_mask=False,\n         num_classes=18,\n         use_predicter=True,\n         class_wise=False,\n+        fast_voxel_gen=None,\n         **kwargs\n     ):\n         super(LetOCC, self).__init__(**kwargs)\n         self.out_dim = out_dim\n"
                },
                {
                    "date": 1720778573514,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -46,8 +46,10 @@\n         self.num_classes = num_classes\n         self.loss_occ = build_loss(loss_occ)\n         self.class_wise = class_wise\n         self.align_after_view_transfromation = False\n+        \n+        # self.fast_voxel_gen\n \n     def loss_single(self, voxel_semantics, mask_camera, preds):\n         loss_ = dict()\n         voxel_semantics = voxel_semantics.long()\n"
                },
                {
                    "date": 1720778586883,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -5,8 +5,9 @@\n from mmdet.models.builder import build_loss\n from mmcv.cnn.bricks.conv_module import ConvModule\n from torch import nn\n import numpy as np\n+import ..builder\n \n \n @DETECTORS.register_module()\n class LetOCC(BEVStereo4D):\n"
                },
                {
                    "date": 1720778587476,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -5,9 +5,9 @@\n from mmdet.models.builder import build_loss\n from mmcv.cnn.bricks.conv_module import ConvModule\n from torch import nn\n import numpy as np\n-import ..builder\n+import ..builder \n \n \n @DETECTORS.register_module()\n class LetOCC(BEVStereo4D):\n"
                },
                {
                    "date": 1720785928572,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -5,9 +5,9 @@\n from mmdet.models.builder import build_loss\n from mmcv.cnn.bricks.conv_module import ConvModule\n from torch import nn\n import numpy as np\n-import ..builder \n+import ..builder as builder\n \n \n @DETECTORS.register_module()\n class LetOCC(BEVStereo4D):\n@@ -48,9 +48,9 @@\n         self.loss_occ = build_loss(loss_occ)\n         self.class_wise = class_wise\n         self.align_after_view_transfromation = False\n         \n-        # self.fast_voxel_gen\n+        self.fast_voxel_gen=builder.build_neck(fast_voxel_gen)\n \n     def loss_single(self, voxel_semantics, mask_camera, preds):\n         loss_ = dict()\n         voxel_semantics = voxel_semantics.long()\n"
                },
                {
                    "date": 1720785956223,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -48,8 +48,9 @@\n         self.loss_occ = build_loss(loss_occ)\n         self.class_wise = class_wise\n         self.align_after_view_transfromation = False\n         \n+        \n         self.fast_voxel_gen=builder.build_neck(fast_voxel_gen)\n \n     def loss_single(self, voxel_semantics, mask_camera, preds):\n         loss_ = dict()\n"
                },
                {
                    "date": 1720785962961,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -49,8 +49,10 @@\n         self.class_wise = class_wise\n         self.align_after_view_transfromation = False\n         \n         \n+        \n+        \n         self.fast_voxel_gen=builder.build_neck(fast_voxel_gen)\n \n     def loss_single(self, voxel_semantics, mask_camera, preds):\n         loss_ = dict()\n"
                },
                {
                    "date": 1720785994282,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -6,8 +6,9 @@\n from mmcv.cnn.bricks.conv_module import ConvModule\n from torch import nn\n import numpy as np\n \n+from .. impo\n \n \n @DETECTORS.register_module()\n class LetOCC(BEVStereo4D):\n"
                },
                {
                    "date": 1721012320041,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -78,9 +78,9 @@\n         img = self.prepare_inputs(img)\n         x, _ = self.image_encoder(img[0])\n \n         # fast voxel gen processing\n-        fast_voxel = self.fast_voxel_gen(x, img_inputs=img[1:],img_metas=img_metas)\n+        fast_voxel = self.fast_voxel_gen(x, img_inputs=img[1:], img_metas=img_metas)\n \n         # slow voxel gen processing\n         x, depth = self.img_view_transformer([x] + img[1:7])\n         x = self.bev_encoder(x)\n"
                }
            ],
            "date": 1720689643857,
            "name": "Commit-0",
            "content": "from .bevdet import BEVStereo4D\n\nimport torch\nfrom mmdet.models import DETECTORS\nfrom mmdet.models.builder import build_loss\nfrom mmcv.cnn.bricks.conv_module import ConvModule\nfrom torch import nn\nimport numpy as np\n\n\n@DETECTORS.register_module()\nclass LetOCC(BEVStereo4D):\n\n    def __init__(\n        self,\n        loss_occ=None,\n        out_dim=32,\n        use_mask=False,\n        num_classes=18,\n        use_predicter=True,\n        class_wise=False,\n        **kwargs\n    ):\n        super(LetOCC, self).__init__(**kwargs)\n        self.out_dim = out_dim\n        out_channels = out_dim if use_predicter else num_classes\n        self.final_conv = ConvModule(\n            self.img_view_transformer.out_channels,\n            out_channels,\n            kernel_size=3,\n            stride=1,\n            padding=1,\n            bias=True,\n            conv_cfg=dict(type=\"Conv3d\"),\n        )\n        self.use_predicter = use_predicter\n        if use_predicter:\n            self.predicter = nn.Sequential(\n                nn.Linear(self.out_dim, self.out_dim * 2),\n                nn.Softplus(),\n                nn.Linear(self.out_dim * 2, num_classes),\n            )\n        self.pts_bbox_head = None\n        self.use_mask = use_mask\n        self.num_classes = num_classes\n        self.loss_occ = build_loss(loss_occ)\n        self.class_wise = class_wise\n        self.align_after_view_transfromation = False\n\n    def loss_single(self, voxel_semantics, mask_camera, preds):\n        loss_ = dict()\n        voxel_semantics = voxel_semantics.long()\n        if self.use_mask:\n            mask_camera = mask_camera.to(torch.int32)\n            voxel_semantics = voxel_semantics.reshape(-1)\n            preds = preds.reshape(-1, self.num_classes)\n            mask_camera = mask_camera.reshape(-1)\n            num_total_samples = mask_camera.sum()\n            loss_occ = self.loss_occ(\n                preds, voxel_semantics, mask_camera, avg_factor=num_total_samples\n            )\n            loss_[\"loss_occ\"] = loss_occ\n        else:\n            voxel_semantics = voxel_semantics.reshape(-1)\n            preds = preds.reshape(-1, self.num_classes)\n            loss_occ = self.loss_occ(\n                preds,\n                voxel_semantics,\n            )\n            loss_[\"loss_occ\"] = loss_occ\n        return loss_\n\n    def simple_test(self, points, img_metas, img=None, rescale=False, **kwargs):\n        \"\"\"Test function without augmentaiton.\"\"\"\n        img_feats, _, _ = self.extract_feat(\n            points, img=img, img_metas=img_metas, **kwargs\n        )\n        occ_pred = self.final_conv(img_feats[0]).permute(0, 4, 3, 2, 1)\n        # bncdhw->bnwhdc\n        if self.use_predicter:\n            occ_pred = self.predicter(occ_pred)\n        occ_score = occ_pred.softmax(-1)\n        occ_res = occ_score.argmax(-1)\n        occ_res = occ_res.squeeze(dim=0).cpu().numpy().astype(np.uint8)\n        return [occ_res]\n\n    def forward_train(\n        self,\n        points=None,\n        img_metas=None,\n        gt_bboxes_3d=None,\n        gt_labels_3d=None,\n        gt_labels=None,\n        gt_bboxes=None,\n        img_inputs=None,\n        proposals=None,\n        gt_bboxes_ignore=None,\n        **kwargs\n    ):\n        \"\"\"Forward training function.\n\n        Args:\n            points (list[torch.Tensor], optional): Points of each sample.\n                Defaults to None.\n            img_metas (list[dict], optional): Meta information of each sample.\n                Defaults to None.\n            gt_bboxes_3d (list[:obj:`BaseInstance3DBoxes`], optional):\n                Ground truth 3D boxes. Defaults to None.\n            gt_labels_3d (list[torch.Tensor], optional): Ground truth labels\n                of 3D boxes. Defaults to None.\n            gt_labels (list[torch.Tensor], optional): Ground truth labels\n                of 2D boxes in images. Defaults to None.\n            gt_bboxes (list[torch.Tensor], optional): Ground truth 2D boxes in\n                images. Defaults to None.\n            img (torch.Tensor optional): Images of each sample with shape\n                (N, C, H, W). Defaults to None.\n            proposals ([list[torch.Tensor], optional): Predicted proposals\n                used for training Fast RCNN. Defaults to None.\n            gt_bboxes_ignore (list[torch.Tensor], optional): Ground truth\n                2D boxes in images to be ignored. Defaults to None.\n\n        Returns:\n            dict: Losses of different branches.\n        \"\"\"\n        img_feats, pts_feats, depth = self.extract_feat(\n            points, img=img_inputs, img_metas=img_metas, **kwargs\n        )\n        gt_depth = kwargs[\"gt_depth\"]\n        losses = dict()\n        loss_depth = self.img_view_transformer.get_depth_loss(gt_depth, depth)\n        losses[\"loss_depth\"] = loss_depth\n\n        occ_pred = self.final_conv(img_feats[0]).permute(\n            0, 4, 3, 2, 1\n        )  # bncdhw->bnwhdc\n        if self.use_predicter:\n            occ_pred = self.predicter(occ_pred)\n        voxel_semantics = kwargs[\"voxel_semantics\"]\n        mask_camera = kwargs[\"mask_camera\"]\n        assert voxel_semantics.min() >= 0 and voxel_semantics.max() <= 17\n        loss_occ = self.loss_single(voxel_semantics, mask_camera, occ_pred)\n        losses.update(loss_occ)\n        return losses\n"
        }
    ]
}