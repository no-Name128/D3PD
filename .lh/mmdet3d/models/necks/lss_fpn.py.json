{
    "sourceFile": "mmdet3d/models/necks/lss_fpn.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1716025145843,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1716025956638,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -11,86 +11,92 @@\n \n @NECKS.register_module()\n class FPN_LSS(nn.Module):\n \n-    def __init__(self,\n-                 in_channels,\n-                 out_channels,\n-                 scale_factor=4,\n-                 input_feature_index=(0, 2),\n-                 norm_cfg=dict(type='BN'),\n-                 extra_upsample=2,\n-                 lateral=None,\n-                 use_input_conv=False):\n+    def __init__(\n+        self,\n+        in_channels,\n+        out_channels,\n+        scale_factor=4,\n+        input_feature_index=(0, 2),\n+        norm_cfg=dict(type=\"BN\"),\n+        extra_upsample=2,\n+        lateral=None,\n+        use_input_conv=False,\n+    ):\n         super().__init__()\n         self.input_feature_index = input_feature_index\n         self.extra_upsample = extra_upsample is not None\n         self.up = nn.Upsample(\n-            scale_factor=scale_factor, mode='bilinear', align_corners=True)\n+            scale_factor=scale_factor, mode=\"bilinear\", align_corners=True\n+        )\n         # assert norm_cfg['type'] in ['BN', 'SyncBN']\n         channels_factor = 2 if self.extra_upsample else 1\n-        self.input_conv = nn.Sequential(\n-            nn.Conv2d(\n-                in_channels,\n-                out_channels * channels_factor,\n-                kernel_size=1,\n-                padding=0,\n-                bias=False),\n-            build_norm_layer(\n-                norm_cfg, out_channels * channels_factor, postfix=0)[1],\n-            nn.ReLU(inplace=True),\n-        ) if use_input_conv else None\n+        self.input_conv = (\n+            nn.Sequential(\n+                nn.Conv2d(\n+                    in_channels,\n+                    out_channels * channels_factor,\n+                    kernel_size=1,\n+                    padding=0,\n+                    bias=False,\n+                ),\n+                build_norm_layer(norm_cfg, out_channels * channels_factor, postfix=0)[\n+                    1\n+                ],\n+                nn.ReLU(inplace=True),\n+            )\n+            if use_input_conv\n+            else None\n+        )\n         if use_input_conv:\n             in_channels = out_channels * channels_factor\n         self.conv = nn.Sequential(\n             nn.Conv2d(\n                 in_channels,\n                 out_channels * channels_factor,\n                 kernel_size=3,\n                 padding=1,\n-                bias=False),\n-            build_norm_layer(\n-                norm_cfg, out_channels * channels_factor, postfix=0)[1],\n+                bias=False,\n+            ),\n+            build_norm_layer(norm_cfg, out_channels * channels_factor, postfix=0)[1],\n             nn.ReLU(inplace=True),\n             nn.Conv2d(\n                 out_channels * channels_factor,\n                 out_channels * channels_factor,\n                 kernel_size=3,\n                 padding=1,\n-                bias=False),\n-            build_norm_layer(\n-                norm_cfg, out_channels * channels_factor, postfix=0)[1],\n+                bias=False,\n+            ),\n+            build_norm_layer(norm_cfg, out_channels * channels_factor, postfix=0)[1],\n             nn.ReLU(inplace=True),\n         )\n         if self.extra_upsample:\n             self.up2 = nn.Sequential(\n                 nn.Upsample(\n-                    scale_factor=extra_upsample,\n-                    mode='bilinear',\n-                    align_corners=True),\n+                    scale_factor=extra_upsample, mode=\"bilinear\", align_corners=True\n+                ),\n                 nn.Conv2d(\n                     out_channels * channels_factor,\n                     out_channels,\n                     kernel_size=3,\n                     padding=1,\n-                    bias=False),\n+                    bias=False,\n+                ),\n                 build_norm_layer(norm_cfg, out_channels, postfix=0)[1],\n                 nn.ReLU(inplace=True),\n-                nn.Conv2d(\n-                    out_channels, out_channels, kernel_size=1, padding=0),\n+                nn.Conv2d(out_channels, out_channels, kernel_size=1, padding=0),\n             )\n         self.lateral = lateral is not None\n         if self.lateral:\n             self.lateral_conv = nn.Sequential(\n-                nn.Conv2d(\n-                    lateral, lateral, kernel_size=1, padding=0, bias=False),\n+                nn.Conv2d(lateral, lateral, kernel_size=1, padding=0, bias=False),\n                 build_norm_layer(norm_cfg, lateral, postfix=0)[1],\n                 nn.ReLU(inplace=True),\n             )\n \n     def forward(self, feats):\n-        x2, x1 = feats[self.input_feature_index[0]], \\\n-                 feats[self.input_feature_index[1]]\n+        x2, x1 = feats[self.input_feature_index[0]], feats[self.input_feature_index[1]]\n         if self.lateral:\n             x2 = self.lateral_conv(x2)\n         x1 = self.up(x1)\n         x = torch.cat([x2, x1], dim=1)\n@@ -100,30 +106,29 @@\n         if self.extra_upsample:\n             x = self.up2(x)\n         return x\n \n+\n @NECKS.register_module()\n class LSSFPN3D(nn.Module):\n-    def __init__(self,\n-                 in_channels,\n-                 out_channels,\n-                 with_cp=False):\n+    def __init__(self, in_channels, out_channels, with_cp=False):\n         super().__init__()\n-        self.up1 =  nn.Upsample(\n-            scale_factor=2, mode='trilinear', align_corners=True)\n-        self.up2 =  nn.Upsample(\n-            scale_factor=4, mode='trilinear', align_corners=True)\n+        self.up1 = nn.Upsample(scale_factor=2, mode=\"trilinear\", align_corners=True)\n+        self.up2 = nn.Upsample(scale_factor=4, mode=\"trilinear\", align_corners=True)\n \n         self.conv = ConvModule(\n             in_channels,\n             out_channels,\n             kernel_size=1,\n             stride=1,\n             padding=0,\n             bias=False,\n-            conv_cfg=dict(type='Conv3d'),\n-            norm_cfg=dict(type='BN3d', ),\n-            act_cfg=dict(type='ReLU',inplace=True))\n+            conv_cfg=dict(type=\"Conv3d\"),\n+            norm_cfg=dict(\n+                type=\"BN3d\",\n+            ),\n+            act_cfg=dict(type=\"ReLU\", inplace=True),\n+        )\n         self.with_cp = with_cp\n \n     def forward(self, feats):\n         x_8, x_16, x_32 = feats\n@@ -133,5 +138,5 @@\n         if self.with_cp:\n             x = checkpoint(self.conv, x)\n         else:\n             x = self.conv(x)\n-        return x\n\\ No newline at end of file\n+        return x\n"
                }
            ],
            "date": 1716025145843,
            "name": "Commit-0",
            "content": "# Copyright (c) Phigent Robotics. All rights reserved.\n\nimport torch\nimport torch.nn as nn\nfrom mmcv.cnn import build_norm_layer\n\nfrom torch.utils.checkpoint import checkpoint\nfrom mmdet3d.models.backbones.resnet import ConvModule\nfrom mmdet.models import NECKS\n\n\n@NECKS.register_module()\nclass FPN_LSS(nn.Module):\n\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 scale_factor=4,\n                 input_feature_index=(0, 2),\n                 norm_cfg=dict(type='BN'),\n                 extra_upsample=2,\n                 lateral=None,\n                 use_input_conv=False):\n        super().__init__()\n        self.input_feature_index = input_feature_index\n        self.extra_upsample = extra_upsample is not None\n        self.up = nn.Upsample(\n            scale_factor=scale_factor, mode='bilinear', align_corners=True)\n        # assert norm_cfg['type'] in ['BN', 'SyncBN']\n        channels_factor = 2 if self.extra_upsample else 1\n        self.input_conv = nn.Sequential(\n            nn.Conv2d(\n                in_channels,\n                out_channels * channels_factor,\n                kernel_size=1,\n                padding=0,\n                bias=False),\n            build_norm_layer(\n                norm_cfg, out_channels * channels_factor, postfix=0)[1],\n            nn.ReLU(inplace=True),\n        ) if use_input_conv else None\n        if use_input_conv:\n            in_channels = out_channels * channels_factor\n        self.conv = nn.Sequential(\n            nn.Conv2d(\n                in_channels,\n                out_channels * channels_factor,\n                kernel_size=3,\n                padding=1,\n                bias=False),\n            build_norm_layer(\n                norm_cfg, out_channels * channels_factor, postfix=0)[1],\n            nn.ReLU(inplace=True),\n            nn.Conv2d(\n                out_channels * channels_factor,\n                out_channels * channels_factor,\n                kernel_size=3,\n                padding=1,\n                bias=False),\n            build_norm_layer(\n                norm_cfg, out_channels * channels_factor, postfix=0)[1],\n            nn.ReLU(inplace=True),\n        )\n        if self.extra_upsample:\n            self.up2 = nn.Sequential(\n                nn.Upsample(\n                    scale_factor=extra_upsample,\n                    mode='bilinear',\n                    align_corners=True),\n                nn.Conv2d(\n                    out_channels * channels_factor,\n                    out_channels,\n                    kernel_size=3,\n                    padding=1,\n                    bias=False),\n                build_norm_layer(norm_cfg, out_channels, postfix=0)[1],\n                nn.ReLU(inplace=True),\n                nn.Conv2d(\n                    out_channels, out_channels, kernel_size=1, padding=0),\n            )\n        self.lateral = lateral is not None\n        if self.lateral:\n            self.lateral_conv = nn.Sequential(\n                nn.Conv2d(\n                    lateral, lateral, kernel_size=1, padding=0, bias=False),\n                build_norm_layer(norm_cfg, lateral, postfix=0)[1],\n                nn.ReLU(inplace=True),\n            )\n\n    def forward(self, feats):\n        x2, x1 = feats[self.input_feature_index[0]], \\\n                 feats[self.input_feature_index[1]]\n        if self.lateral:\n            x2 = self.lateral_conv(x2)\n        x1 = self.up(x1)\n        x = torch.cat([x2, x1], dim=1)\n        if self.input_conv is not None:\n            x = self.input_conv(x)\n        x = self.conv(x)\n        if self.extra_upsample:\n            x = self.up2(x)\n        return x\n\n@NECKS.register_module()\nclass LSSFPN3D(nn.Module):\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 with_cp=False):\n        super().__init__()\n        self.up1 =  nn.Upsample(\n            scale_factor=2, mode='trilinear', align_corners=True)\n        self.up2 =  nn.Upsample(\n            scale_factor=4, mode='trilinear', align_corners=True)\n\n        self.conv = ConvModule(\n            in_channels,\n            out_channels,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n            bias=False,\n            conv_cfg=dict(type='Conv3d'),\n            norm_cfg=dict(type='BN3d', ),\n            act_cfg=dict(type='ReLU',inplace=True))\n        self.with_cp = with_cp\n\n    def forward(self, feats):\n        x_8, x_16, x_32 = feats\n        x_16 = self.up1(x_16)\n        x_32 = self.up2(x_32)\n        x = torch.cat([x_8, x_16, x_32], dim=1)\n        if self.with_cp:\n            x = checkpoint(self.conv, x)\n        else:\n            x = self.conv(x)\n        return x"
        }
    ]
}