{
    "sourceFile": "mmdet3d/apis/test.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1740707651920,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1740707651920,
            "name": "Commit-0",
            "content": "# Copyright (c) OpenMMLab. All rights reserved.\nfrom os import path as osp\n\nimport mmcv\nimport torch\nfrom mmcv.image import tensor2imgs\n\nfrom mmdet3d.models import (Base3DDetector, Base3DSegmentor,\n                            SingleStageMono3DDetector)\n\n\ndef single_gpu_test(model,\n                    data_loader,\n                    show=False,\n                    out_dir=None,\n                    show_score_thr=0.3):\n    \"\"\"Test model with single gpu.\n\n    This method tests model with single gpu and gives the 'show' option.\n    By setting ``show=True``, it saves the visualization results under\n    ``out_dir``.\n\n    Args:\n        model (nn.Module): Model to be tested.\n        data_loader (nn.Dataloader): Pytorch data loader.\n        show (bool, optional): Whether to save viualization results.\n            Default: True.\n        out_dir (str, optional): The path to save visualization results.\n            Default: None.\n\n    Returns:\n        list[dict]: The prediction results.\n    \"\"\"\n    model.eval()\n    results = []\n    dataset = data_loader.dataset\n    prog_bar = mmcv.ProgressBar(len(dataset))\n    for i, data in enumerate(data_loader):\n        with torch.no_grad():\n            result = model(return_loss=False, rescale=True, **data)\n\n        if show:\n            # Visualize the results of MMDetection3D model\n            # 'show_results' is MMdetection3D visualization API\n            models_3d = (Base3DDetector, Base3DSegmentor,\n                         SingleStageMono3DDetector)\n            if isinstance(model.module, models_3d):\n                model.module.show_results(\n                    data,\n                    result,\n                    out_dir=out_dir,\n                    show=show,\n                    score_thr=show_score_thr)\n            # Visualize the results of MMDetection model\n            # 'show_result' is MMdetection visualization API\n            else:\n                batch_size = len(result)\n                if batch_size == 1 and isinstance(data['img'][0],\n                                                  torch.Tensor):\n                    img_tensor = data['img'][0]\n                else:\n                    img_tensor = data['img'][0].data[0]\n                img_metas = data['img_metas'][0].data[0]\n                imgs = tensor2imgs(img_tensor, **img_metas[0]['img_norm_cfg'])\n                assert len(imgs) == len(img_metas)\n\n                for i, (img, img_meta) in enumerate(zip(imgs, img_metas)):\n                    h, w, _ = img_meta['img_shape']\n                    img_show = img[:h, :w, :]\n\n                    ori_h, ori_w = img_meta['ori_shape'][:-1]\n                    img_show = mmcv.imresize(img_show, (ori_w, ori_h))\n\n                    if out_dir:\n                        out_file = osp.join(out_dir, img_meta['ori_filename'])\n                    else:\n                        out_file = None\n\n                    model.module.show_result(\n                        img_show,\n                        result[i],\n                        show=show,\n                        out_file=out_file,\n                        score_thr=show_score_thr)\n        results.extend(result)\n\n        batch_size = len(result)\n        for _ in range(batch_size):\n            prog_bar.update()\n    return results\n"
        }
    ]
}