{
    "sourceFile": "mmdet3d/apis/train.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 4,
            "patches": [
                {
                    "date": 1716017727626,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1716017806031,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -212,9 +212,9 @@\n             # `num_gpus` will be ignored if distributed\n             num_gpus=len(cfg.gpu_ids),\n             dist=distributed,\n             seed=cfg.seed,\n-            runner_type=runner_type,\n+            # runner_type=runner_type,\n             persistent_workers=cfg.data.get('persistent_workers', False))\n         for ds in dataset\n     ]\n \n"
                },
                {
                    "date": 1716023110275,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -213,8 +213,9 @@\n             num_gpus=len(cfg.gpu_ids),\n             dist=distributed,\n             seed=cfg.seed,\n             # runner_type=runner_type,\n+            dataset_scale=cfg.data.get(\"dataset_scale\",2)，\n             persistent_workers=cfg.data.get('persistent_workers', False))\n         for ds in dataset\n     ]\n \n"
                },
                {
                    "date": 1716023220403,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -4,11 +4,18 @@\n \n import numpy as np\n import torch\n from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n-from mmcv.runner import (HOOKS, DistSamplerSeedHook, EpochBasedRunner,\n-                         Fp16OptimizerHook, OptimizerHook, build_optimizer,\n-                         build_runner, get_dist_info)\n+from mmcv.runner import (\n+    HOOKS,\n+    DistSamplerSeedHook,\n+    EpochBasedRunner,\n+    Fp16OptimizerHook,\n+    OptimizerHook,\n+    build_optimizer,\n+    build_runner,\n+    get_dist_info,\n+)\n from mmcv.utils import build_from_cfg\n from torch import distributed as dist\n \n from mmdet3d.datasets import build_dataset\n@@ -23,9 +30,9 @@\n from mmseg.datasets import build_dataloader as build_mmseg_dataloader\n from mmseg.utils import get_root_logger as get_mmseg_root_logger\n \n \n-def init_random_seed(seed=None, device='cuda'):\n+def init_random_seed(seed=None, device=\"cuda\"):\n     \"\"\"Initialize random seed.\n \n     If the seed is not set, the seed will be automatically randomized,\n     and then broadcast to all processes to prevent some potential bugs.\n@@ -73,15 +80,11 @@\n         torch.backends.cudnn.deterministic = True\n         torch.backends.cudnn.benchmark = False\n \n \n-def train_segmentor(model,\n-                    dataset,\n-                    cfg,\n-                    distributed=False,\n-                    validate=False,\n-                    timestamp=None,\n-                    meta=None):\n+def train_segmentor(\n+    model, dataset, cfg, distributed=False, validate=False, timestamp=None, meta=None\n+):\n     \"\"\"Launch segmentor training.\"\"\"\n     logger = get_mmseg_root_logger(cfg.log_level)\n \n     # prepare data loaders\n@@ -94,33 +97,37 @@\n             # cfg.gpus will be ignored if distributed\n             len(cfg.gpu_ids),\n             dist=distributed,\n             seed=cfg.seed,\n-            drop_last=True) for ds in dataset\n+            drop_last=True,\n+        )\n+        for ds in dataset\n     ]\n \n     # put model on gpus\n     if distributed:\n-        find_unused_parameters = cfg.get('find_unused_parameters', False)\n+        find_unused_parameters = cfg.get(\"find_unused_parameters\", False)\n         # Sets the `find_unused_parameters` parameter in\n         # torch.nn.parallel.DistributedDataParallel\n         model = MMDistributedDataParallel(\n             model.cuda(),\n             device_ids=[torch.cuda.current_device()],\n             broadcast_buffers=False,\n-            find_unused_parameters=find_unused_parameters)\n+            find_unused_parameters=find_unused_parameters,\n+        )\n     else:\n-        model = MMDataParallel(\n-            model.cuda(cfg.gpu_ids[0]), device_ids=cfg.gpu_ids)\n+        model = MMDataParallel(model.cuda(cfg.gpu_ids[0]), device_ids=cfg.gpu_ids)\n \n     # build runner\n     optimizer = build_optimizer(model, cfg.optimizer)\n \n-    if cfg.get('runner') is None:\n-        cfg.runner = {'type': 'IterBasedRunner', 'max_iters': cfg.total_iters}\n+    if cfg.get(\"runner\") is None:\n+        cfg.runner = {\"type\": \"IterBasedRunner\", \"max_iters\": cfg.total_iters}\n         warnings.warn(\n-            'config is now expected to have a `runner` section, '\n-            'please set `runner` in your config.', UserWarning)\n+            \"config is now expected to have a `runner` section, \"\n+            \"please set `runner` in your config.\",\n+            UserWarning,\n+        )\n \n     runner = build_runner(\n         cfg.runner,\n         default_args=dict(\n@@ -128,14 +135,20 @@\n             batch_processor=None,\n             optimizer=optimizer,\n             work_dir=cfg.work_dir,\n             logger=logger,\n-            meta=meta))\n+            meta=meta,\n+        ),\n+    )\n \n     # register hooks\n-    runner.register_training_hooks(cfg.lr_config, cfg.optimizer_config,\n-                                   cfg.checkpoint_config, cfg.log_config,\n-                                   cfg.get('momentum_config', None))\n+    runner.register_training_hooks(\n+        cfg.lr_config,\n+        cfg.optimizer_config,\n+        cfg.checkpoint_config,\n+        cfg.log_config,\n+        cfg.get(\"momentum_config\", None),\n+    )\n \n     # an ugly walkaround to make the .log and .log.json filenames the same\n     runner.timestamp = timestamp\n \n@@ -146,28 +159,30 @@\n             val_dataset,\n             samples_per_gpu=1,\n             workers_per_gpu=cfg.data.workers_per_gpu,\n             dist=distributed,\n-            shuffle=False)\n-        eval_cfg = cfg.get('evaluation', {})\n-        eval_cfg['by_epoch'] = cfg.runner['type'] != 'IterBasedRunner'\n+            shuffle=False,\n+        )\n+        eval_cfg = cfg.get(\"evaluation\", {})\n+        eval_cfg[\"by_epoch\"] = cfg.runner[\"type\"] != \"IterBasedRunner\"\n         eval_hook = MMSEG_DistEvalHook if distributed else MMSEG_EvalHook\n         # In this PR (https://github.com/open-mmlab/mmcv/pull/1193), the\n         # priority of IterTimerHook has been modified from 'NORMAL' to 'LOW'.\n-        runner.register_hook(\n-            eval_hook(val_dataloader, **eval_cfg), priority='LOW')\n+        runner.register_hook(eval_hook(val_dataloader, **eval_cfg), priority=\"LOW\")\n \n     # user-defined hooks\n-    if cfg.get('custom_hooks', None):\n+    if cfg.get(\"custom_hooks\", None):\n         custom_hooks = cfg.custom_hooks\n-        assert isinstance(custom_hooks, list), \\\n-            f'custom_hooks expect list type, but got {type(custom_hooks)}'\n+        assert isinstance(\n+            custom_hooks, list\n+        ), f\"custom_hooks expect list type, but got {type(custom_hooks)}\"\n         for hook_cfg in cfg.custom_hooks:\n-            assert isinstance(hook_cfg, dict), \\\n-                'Each item in custom_hooks expects dict type, but got ' \\\n-                f'{type(hook_cfg)}'\n+            assert isinstance(hook_cfg, dict), (\n+                \"Each item in custom_hooks expects dict type, but got \"\n+                f\"{type(hook_cfg)}\"\n+            )\n             hook_cfg = hook_cfg.copy()\n-            priority = hook_cfg.pop('priority', 'NORMAL')\n+            priority = hook_cfg.pop(\"priority\", \"NORMAL\")\n             hook = build_from_cfg(hook_cfg, HOOKS)\n             runner.register_hook(hook, priority=priority)\n \n     if cfg.resume_from:\n@@ -176,35 +191,34 @@\n         runner.load_checkpoint(cfg.load_from)\n     runner.run(data_loaders, cfg.workflow)\n \n \n-def train_detector(model,\n-                   dataset,\n-                   cfg,\n-                   distributed=False,\n-                   validate=False,\n-                   timestamp=None,\n-                   meta=None):\n+def train_detector(\n+    model, dataset, cfg, distributed=False, validate=False, timestamp=None, meta=None\n+):\n     logger = get_mmdet_root_logger(log_level=cfg.log_level)\n \n     # prepare data loaders\n     dataset = dataset if isinstance(dataset, (list, tuple)) else [dataset]\n-    if 'imgs_per_gpu' in cfg.data:\n-        logger.warning('\"imgs_per_gpu\" is deprecated in MMDet V2.0. '\n-                       'Please use \"samples_per_gpu\" instead')\n-        if 'samples_per_gpu' in cfg.data:\n+    if \"imgs_per_gpu\" in cfg.data:\n+        logger.warning(\n+            '\"imgs_per_gpu\" is deprecated in MMDet V2.0. '\n+            'Please use \"samples_per_gpu\" instead'\n+        )\n+        if \"samples_per_gpu\" in cfg.data:\n             logger.warning(\n                 f'Got \"imgs_per_gpu\"={cfg.data.imgs_per_gpu} and '\n                 f'\"samples_per_gpu\"={cfg.data.samples_per_gpu}, \"imgs_per_gpu\"'\n-                f'={cfg.data.imgs_per_gpu} is used in this experiments')\n+                f\"={cfg.data.imgs_per_gpu} is used in this experiments\"\n+            )\n         else:\n             logger.warning(\n                 'Automatically set \"samples_per_gpu\"=\"imgs_per_gpu\"='\n-                f'{cfg.data.imgs_per_gpu} in this experiments')\n+                f\"{cfg.data.imgs_per_gpu} in this experiments\"\n+            )\n         cfg.data.samples_per_gpu = cfg.data.imgs_per_gpu\n \n-    runner_type = 'EpochBasedRunner' if 'runner' not in cfg else cfg.runner[\n-        'type']\n+    runner_type = \"EpochBasedRunner\" if \"runner\" not in cfg else cfg.runner[\"type\"]\n     data_loaders = [\n         build_mmdet_dataloader(\n             ds,\n             cfg.data.samples_per_gpu,\n@@ -213,40 +227,40 @@\n             num_gpus=len(cfg.gpu_ids),\n             dist=distributed,\n             seed=cfg.seed,\n             # runner_type=runner_type,\n-            dataset_scale=cfg.data.get(\"dataset_scale\",2)，\n-            persistent_workers=cfg.data.get('persistent_workers', False))\n+            dataset_scale=cfg.data.get(\"dataset_scale\", 2),\n+            persistent_workers=cfg.data.get(\"persistent_workers\", False),\n+        )\n         for ds in dataset\n     ]\n \n     # put model on gpus\n     if distributed:\n-        find_unused_parameters = cfg.get('find_unused_parameters', False)\n+        find_unused_parameters = cfg.get(\"find_unused_parameters\", False)\n         # Sets the `find_unused_parameters` parameter in\n         # torch.nn.parallel.DistributedDataParallel\n         model = MMDistributedDataParallel(\n             model.cuda(),\n             device_ids=[torch.cuda.current_device()],\n             broadcast_buffers=False,\n-            find_unused_parameters=find_unused_parameters)\n+            find_unused_parameters=find_unused_parameters,\n+        )\n     else:\n-        model = MMDataParallel(\n-            model.cuda(cfg.gpu_ids[0]), device_ids=cfg.gpu_ids)\n+        model = MMDataParallel(model.cuda(cfg.gpu_ids[0]), device_ids=cfg.gpu_ids)\n \n     # build runner\n     optimizer = build_optimizer(model, cfg.optimizer)\n \n-    if 'runner' not in cfg:\n-        cfg.runner = {\n-            'type': 'EpochBasedRunner',\n-            'max_epochs': cfg.total_epochs\n-        }\n+    if \"runner\" not in cfg:\n+        cfg.runner = {\"type\": \"EpochBasedRunner\", \"max_epochs\": cfg.total_epochs}\n         warnings.warn(\n-            'config is now expected to have a `runner` section, '\n-            'please set `runner` in your config.', UserWarning)\n+            \"config is now expected to have a `runner` section, \"\n+            \"please set `runner` in your config.\",\n+            UserWarning,\n+        )\n     else:\n-        if 'total_epochs' in cfg:\n+        if \"total_epochs\" in cfg:\n             assert cfg.total_epochs == cfg.runner.max_epochs\n \n     runner = build_runner(\n         cfg.runner,\n@@ -254,19 +268,22 @@\n             model=model,\n             optimizer=optimizer,\n             work_dir=cfg.work_dir,\n             logger=logger,\n-            meta=meta))\n+            meta=meta,\n+        ),\n+    )\n \n     # an ugly workaround to make .log and .log.json filenames the same\n     runner.timestamp = timestamp\n \n     # fp16 setting\n-    fp16_cfg = cfg.get('fp16', None)\n+    fp16_cfg = cfg.get(\"fp16\", None)\n     if fp16_cfg is not None:\n         optimizer_config = Fp16OptimizerHook(\n-            **cfg.optimizer_config, **fp16_cfg, distributed=distributed)\n-    elif distributed and 'type' not in cfg.optimizer_config:\n+            **cfg.optimizer_config, **fp16_cfg, distributed=distributed\n+        )\n+    elif distributed and \"type\" not in cfg.optimizer_config:\n         optimizer_config = OptimizerHook(**cfg.optimizer_config)\n     else:\n         optimizer_config = cfg.optimizer_config\n \n@@ -275,40 +292,40 @@\n         cfg.lr_config,\n         optimizer_config,\n         cfg.checkpoint_config,\n         cfg.log_config,\n-        cfg.get('momentum_config', None),\n-        custom_hooks_config=cfg.get('custom_hooks', None))\n+        cfg.get(\"momentum_config\", None),\n+        custom_hooks_config=cfg.get(\"custom_hooks\", None),\n+    )\n \n     if distributed:\n         if isinstance(runner, EpochBasedRunner):\n             runner.register_hook(DistSamplerSeedHook())\n \n     # register eval hooks\n     if validate:\n         # Support batch_size > 1 in validation\n-        val_samples_per_gpu = cfg.data.val.pop('samples_per_gpu', 1)\n+        val_samples_per_gpu = cfg.data.val.pop(\"samples_per_gpu\", 1)\n         if val_samples_per_gpu > 1:\n             # Replace 'ImageToTensor' to 'DefaultFormatBundle'\n-            cfg.data.val.pipeline = replace_ImageToTensor(\n-                cfg.data.val.pipeline)\n+            cfg.data.val.pipeline = replace_ImageToTensor(cfg.data.val.pipeline)\n         val_dataset = build_dataset(cfg.data.val, dict(test_mode=True))\n         val_dataloader = build_mmdet_dataloader(\n             val_dataset,\n             samples_per_gpu=val_samples_per_gpu,\n             workers_per_gpu=cfg.data.workers_per_gpu,\n             dist=distributed,\n-            shuffle=False)\n-        eval_cfg = cfg.get('evaluation', {})\n-        eval_cfg['by_epoch'] = cfg.runner['type'] != 'IterBasedRunner'\n+            shuffle=False,\n+        )\n+        eval_cfg = cfg.get(\"evaluation\", {})\n+        eval_cfg[\"by_epoch\"] = cfg.runner[\"type\"] != \"IterBasedRunner\"\n         eval_hook = MMDET_DistEvalHook if distributed else MMDET_EvalHook\n         # In this PR (https://github.com/open-mmlab/mmcv/pull/1193), the\n         # priority of IterTimerHook has been modified from 'NORMAL' to 'LOW'.\n-        runner.register_hook(\n-            eval_hook(val_dataloader, **eval_cfg), priority='LOW')\n+        runner.register_hook(eval_hook(val_dataloader, **eval_cfg), priority=\"LOW\")\n \n     resume_from = None\n-    if cfg.resume_from is None and cfg.get('auto_resume'):\n+    if cfg.resume_from is None and cfg.get(\"auto_resume\"):\n         resume_from = find_latest_checkpoint(cfg.work_dir)\n \n     if resume_from is not None:\n         cfg.resume_from = resume_from\n@@ -319,34 +336,32 @@\n         runner.load_checkpoint(cfg.load_from)\n     runner.run(data_loaders, cfg.workflow)\n \n \n-def train_model(model,\n-                dataset,\n-                cfg,\n-                distributed=False,\n-                validate=False,\n-                timestamp=None,\n-                meta=None):\n+def train_model(\n+    model, dataset, cfg, distributed=False, validate=False, timestamp=None, meta=None\n+):\n     \"\"\"A function wrapper for launching model training according to cfg.\n \n     Because we need different eval_hook in runner. Should be deprecated in the\n     future.\n     \"\"\"\n-    if cfg.model.type in ['EncoderDecoder3D']:\n+    if cfg.model.type in [\"EncoderDecoder3D\"]:\n         train_segmentor(\n             model,\n             dataset,\n             cfg,\n             distributed=distributed,\n             validate=validate,\n             timestamp=timestamp,\n-            meta=meta)\n+            meta=meta,\n+        )\n     else:\n         train_detector(\n             model,\n             dataset,\n             cfg,\n             distributed=distributed,\n             validate=validate,\n             timestamp=timestamp,\n-            meta=meta)\n+            meta=meta,\n+        )\n"
                },
                {
                    "date": 1716023276017,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -227,10 +227,10 @@\n             num_gpus=len(cfg.gpu_ids),\n             dist=distributed,\n             seed=cfg.seed,\n             # runner_type=runner_type,\n+            persistent_workers=cfg.data.get(\"persistent_workers\", False),\n             dataset_scale=cfg.data.get(\"dataset_scale\", 2),\n-            persistent_workers=cfg.data.get(\"persistent_workers\", False),\n         )\n         for ds in dataset\n     ]\n \n"
                }
            ],
            "date": 1716017727626,
            "name": "Commit-0",
            "content": "# Copyright (c) OpenMMLab. All rights reserved.\nimport random\nimport warnings\n\nimport numpy as np\nimport torch\nfrom mmcv.parallel import MMDataParallel, MMDistributedDataParallel\nfrom mmcv.runner import (HOOKS, DistSamplerSeedHook, EpochBasedRunner,\n                         Fp16OptimizerHook, OptimizerHook, build_optimizer,\n                         build_runner, get_dist_info)\nfrom mmcv.utils import build_from_cfg\nfrom torch import distributed as dist\n\nfrom mmdet3d.datasets import build_dataset\nfrom mmdet3d.utils import find_latest_checkpoint\nfrom mmdet.core import DistEvalHook as MMDET_DistEvalHook\nfrom mmdet.core import EvalHook as MMDET_EvalHook\nfrom mmdet.datasets import build_dataloader as build_mmdet_dataloader\nfrom mmdet.datasets import replace_ImageToTensor\nfrom mmdet.utils import get_root_logger as get_mmdet_root_logger\nfrom mmseg.core import DistEvalHook as MMSEG_DistEvalHook\nfrom mmseg.core import EvalHook as MMSEG_EvalHook\nfrom mmseg.datasets import build_dataloader as build_mmseg_dataloader\nfrom mmseg.utils import get_root_logger as get_mmseg_root_logger\n\n\ndef init_random_seed(seed=None, device='cuda'):\n    \"\"\"Initialize random seed.\n\n    If the seed is not set, the seed will be automatically randomized,\n    and then broadcast to all processes to prevent some potential bugs.\n    Args:\n        seed (int, optional): The seed. Default to None.\n        device (str, optional): The device where the seed will be put on.\n            Default to 'cuda'.\n    Returns:\n        int: Seed to be used.\n    \"\"\"\n    if seed is not None:\n        return seed\n\n    # Make sure all ranks share the same random seed to prevent\n    # some potential bugs. Please refer to\n    # https://github.com/open-mmlab/mmdetection/issues/6339\n    rank, world_size = get_dist_info()\n    seed = np.random.randint(2**31)\n    if world_size == 1:\n        return seed\n\n    if rank == 0:\n        random_num = torch.tensor(seed, dtype=torch.int32, device=device)\n    else:\n        random_num = torch.tensor(0, dtype=torch.int32, device=device)\n    dist.broadcast(random_num, src=0)\n    return random_num.item()\n\n\ndef set_random_seed(seed, deterministic=False):\n    \"\"\"Set random seed.\n\n    Args:\n        seed (int): Seed to be used.\n        deterministic (bool): Whether to set the deterministic option for\n            CUDNN backend, i.e., set `torch.backends.cudnn.deterministic`\n            to True and `torch.backends.cudnn.benchmark` to False.\n            Default: False.\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    if deterministic:\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\n\ndef train_segmentor(model,\n                    dataset,\n                    cfg,\n                    distributed=False,\n                    validate=False,\n                    timestamp=None,\n                    meta=None):\n    \"\"\"Launch segmentor training.\"\"\"\n    logger = get_mmseg_root_logger(cfg.log_level)\n\n    # prepare data loaders\n    dataset = dataset if isinstance(dataset, (list, tuple)) else [dataset]\n    data_loaders = [\n        build_mmseg_dataloader(\n            ds,\n            cfg.data.samples_per_gpu,\n            cfg.data.workers_per_gpu,\n            # cfg.gpus will be ignored if distributed\n            len(cfg.gpu_ids),\n            dist=distributed,\n            seed=cfg.seed,\n            drop_last=True) for ds in dataset\n    ]\n\n    # put model on gpus\n    if distributed:\n        find_unused_parameters = cfg.get('find_unused_parameters', False)\n        # Sets the `find_unused_parameters` parameter in\n        # torch.nn.parallel.DistributedDataParallel\n        model = MMDistributedDataParallel(\n            model.cuda(),\n            device_ids=[torch.cuda.current_device()],\n            broadcast_buffers=False,\n            find_unused_parameters=find_unused_parameters)\n    else:\n        model = MMDataParallel(\n            model.cuda(cfg.gpu_ids[0]), device_ids=cfg.gpu_ids)\n\n    # build runner\n    optimizer = build_optimizer(model, cfg.optimizer)\n\n    if cfg.get('runner') is None:\n        cfg.runner = {'type': 'IterBasedRunner', 'max_iters': cfg.total_iters}\n        warnings.warn(\n            'config is now expected to have a `runner` section, '\n            'please set `runner` in your config.', UserWarning)\n\n    runner = build_runner(\n        cfg.runner,\n        default_args=dict(\n            model=model,\n            batch_processor=None,\n            optimizer=optimizer,\n            work_dir=cfg.work_dir,\n            logger=logger,\n            meta=meta))\n\n    # register hooks\n    runner.register_training_hooks(cfg.lr_config, cfg.optimizer_config,\n                                   cfg.checkpoint_config, cfg.log_config,\n                                   cfg.get('momentum_config', None))\n\n    # an ugly walkaround to make the .log and .log.json filenames the same\n    runner.timestamp = timestamp\n\n    # register eval hooks\n    if validate:\n        val_dataset = build_dataset(cfg.data.val, dict(test_mode=True))\n        val_dataloader = build_mmseg_dataloader(\n            val_dataset,\n            samples_per_gpu=1,\n            workers_per_gpu=cfg.data.workers_per_gpu,\n            dist=distributed,\n            shuffle=False)\n        eval_cfg = cfg.get('evaluation', {})\n        eval_cfg['by_epoch'] = cfg.runner['type'] != 'IterBasedRunner'\n        eval_hook = MMSEG_DistEvalHook if distributed else MMSEG_EvalHook\n        # In this PR (https://github.com/open-mmlab/mmcv/pull/1193), the\n        # priority of IterTimerHook has been modified from 'NORMAL' to 'LOW'.\n        runner.register_hook(\n            eval_hook(val_dataloader, **eval_cfg), priority='LOW')\n\n    # user-defined hooks\n    if cfg.get('custom_hooks', None):\n        custom_hooks = cfg.custom_hooks\n        assert isinstance(custom_hooks, list), \\\n            f'custom_hooks expect list type, but got {type(custom_hooks)}'\n        for hook_cfg in cfg.custom_hooks:\n            assert isinstance(hook_cfg, dict), \\\n                'Each item in custom_hooks expects dict type, but got ' \\\n                f'{type(hook_cfg)}'\n            hook_cfg = hook_cfg.copy()\n            priority = hook_cfg.pop('priority', 'NORMAL')\n            hook = build_from_cfg(hook_cfg, HOOKS)\n            runner.register_hook(hook, priority=priority)\n\n    if cfg.resume_from:\n        runner.resume(cfg.resume_from)\n    elif cfg.load_from:\n        runner.load_checkpoint(cfg.load_from)\n    runner.run(data_loaders, cfg.workflow)\n\n\ndef train_detector(model,\n                   dataset,\n                   cfg,\n                   distributed=False,\n                   validate=False,\n                   timestamp=None,\n                   meta=None):\n    logger = get_mmdet_root_logger(log_level=cfg.log_level)\n\n    # prepare data loaders\n    dataset = dataset if isinstance(dataset, (list, tuple)) else [dataset]\n    if 'imgs_per_gpu' in cfg.data:\n        logger.warning('\"imgs_per_gpu\" is deprecated in MMDet V2.0. '\n                       'Please use \"samples_per_gpu\" instead')\n        if 'samples_per_gpu' in cfg.data:\n            logger.warning(\n                f'Got \"imgs_per_gpu\"={cfg.data.imgs_per_gpu} and '\n                f'\"samples_per_gpu\"={cfg.data.samples_per_gpu}, \"imgs_per_gpu\"'\n                f'={cfg.data.imgs_per_gpu} is used in this experiments')\n        else:\n            logger.warning(\n                'Automatically set \"samples_per_gpu\"=\"imgs_per_gpu\"='\n                f'{cfg.data.imgs_per_gpu} in this experiments')\n        cfg.data.samples_per_gpu = cfg.data.imgs_per_gpu\n\n    runner_type = 'EpochBasedRunner' if 'runner' not in cfg else cfg.runner[\n        'type']\n    data_loaders = [\n        build_mmdet_dataloader(\n            ds,\n            cfg.data.samples_per_gpu,\n            cfg.data.workers_per_gpu,\n            # `num_gpus` will be ignored if distributed\n            num_gpus=len(cfg.gpu_ids),\n            dist=distributed,\n            seed=cfg.seed,\n            runner_type=runner_type,\n            persistent_workers=cfg.data.get('persistent_workers', False))\n        for ds in dataset\n    ]\n\n    # put model on gpus\n    if distributed:\n        find_unused_parameters = cfg.get('find_unused_parameters', False)\n        # Sets the `find_unused_parameters` parameter in\n        # torch.nn.parallel.DistributedDataParallel\n        model = MMDistributedDataParallel(\n            model.cuda(),\n            device_ids=[torch.cuda.current_device()],\n            broadcast_buffers=False,\n            find_unused_parameters=find_unused_parameters)\n    else:\n        model = MMDataParallel(\n            model.cuda(cfg.gpu_ids[0]), device_ids=cfg.gpu_ids)\n\n    # build runner\n    optimizer = build_optimizer(model, cfg.optimizer)\n\n    if 'runner' not in cfg:\n        cfg.runner = {\n            'type': 'EpochBasedRunner',\n            'max_epochs': cfg.total_epochs\n        }\n        warnings.warn(\n            'config is now expected to have a `runner` section, '\n            'please set `runner` in your config.', UserWarning)\n    else:\n        if 'total_epochs' in cfg:\n            assert cfg.total_epochs == cfg.runner.max_epochs\n\n    runner = build_runner(\n        cfg.runner,\n        default_args=dict(\n            model=model,\n            optimizer=optimizer,\n            work_dir=cfg.work_dir,\n            logger=logger,\n            meta=meta))\n\n    # an ugly workaround to make .log and .log.json filenames the same\n    runner.timestamp = timestamp\n\n    # fp16 setting\n    fp16_cfg = cfg.get('fp16', None)\n    if fp16_cfg is not None:\n        optimizer_config = Fp16OptimizerHook(\n            **cfg.optimizer_config, **fp16_cfg, distributed=distributed)\n    elif distributed and 'type' not in cfg.optimizer_config:\n        optimizer_config = OptimizerHook(**cfg.optimizer_config)\n    else:\n        optimizer_config = cfg.optimizer_config\n\n    # register hooks\n    runner.register_training_hooks(\n        cfg.lr_config,\n        optimizer_config,\n        cfg.checkpoint_config,\n        cfg.log_config,\n        cfg.get('momentum_config', None),\n        custom_hooks_config=cfg.get('custom_hooks', None))\n\n    if distributed:\n        if isinstance(runner, EpochBasedRunner):\n            runner.register_hook(DistSamplerSeedHook())\n\n    # register eval hooks\n    if validate:\n        # Support batch_size > 1 in validation\n        val_samples_per_gpu = cfg.data.val.pop('samples_per_gpu', 1)\n        if val_samples_per_gpu > 1:\n            # Replace 'ImageToTensor' to 'DefaultFormatBundle'\n            cfg.data.val.pipeline = replace_ImageToTensor(\n                cfg.data.val.pipeline)\n        val_dataset = build_dataset(cfg.data.val, dict(test_mode=True))\n        val_dataloader = build_mmdet_dataloader(\n            val_dataset,\n            samples_per_gpu=val_samples_per_gpu,\n            workers_per_gpu=cfg.data.workers_per_gpu,\n            dist=distributed,\n            shuffle=False)\n        eval_cfg = cfg.get('evaluation', {})\n        eval_cfg['by_epoch'] = cfg.runner['type'] != 'IterBasedRunner'\n        eval_hook = MMDET_DistEvalHook if distributed else MMDET_EvalHook\n        # In this PR (https://github.com/open-mmlab/mmcv/pull/1193), the\n        # priority of IterTimerHook has been modified from 'NORMAL' to 'LOW'.\n        runner.register_hook(\n            eval_hook(val_dataloader, **eval_cfg), priority='LOW')\n\n    resume_from = None\n    if cfg.resume_from is None and cfg.get('auto_resume'):\n        resume_from = find_latest_checkpoint(cfg.work_dir)\n\n    if resume_from is not None:\n        cfg.resume_from = resume_from\n\n    if cfg.resume_from:\n        runner.resume(cfg.resume_from)\n    elif cfg.load_from:\n        runner.load_checkpoint(cfg.load_from)\n    runner.run(data_loaders, cfg.workflow)\n\n\ndef train_model(model,\n                dataset,\n                cfg,\n                distributed=False,\n                validate=False,\n                timestamp=None,\n                meta=None):\n    \"\"\"A function wrapper for launching model training according to cfg.\n\n    Because we need different eval_hook in runner. Should be deprecated in the\n    future.\n    \"\"\"\n    if cfg.model.type in ['EncoderDecoder3D']:\n        train_segmentor(\n            model,\n            dataset,\n            cfg,\n            distributed=distributed,\n            validate=validate,\n            timestamp=timestamp,\n            meta=meta)\n    else:\n        train_detector(\n            model,\n            dataset,\n            cfg,\n            distributed=distributed,\n            validate=validate,\n            timestamp=timestamp,\n            meta=meta)\n"
        }
    ]
}